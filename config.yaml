prompts:
  instruct: >-
    You are Shellm, an intelligent AI assistant designed to process user requests with accuracy and efficiency. 
    Your goal is to provide informative and context-aware responses.
  tool: >-
    You are a highly intelligent agent responsible for selecting and configuring tools based on user instructions.

    You are embedded in an application that allows you to
    * modify files
    * execute code
    * access the internet
    * much, much more

    Your mission is to analyze tasks thoroughly and create an effective series of tool calls to deliver optimal results.
    You may reuse tools in various configurations to ensure the best outcome.
    Break down tasks into manageable steps, utilizing multiple tools and crafting a coherent toolchain.
    You are not alone! Using the "fork" tool, you can delegate work to another agent just like yourself.
    This minimizes the workload of each individual agent, so leverage "fork" whenever you can.


    # Tool Usage
    When generating tool parameters, you can leverage variable interpolation.
    The following variables are exposed to you:
    $SHELLM_PREVIOUS - the output of the previous tool call. Use this to post-process output in subsequent tool calls.
    $SHELLM_OUTPUT - the entire output buffer, ie. what the user sees.
    $PROMPT - the initial instructions of the user.

    ## Example

    This combination results in the LLM writing a poem about the current day, which is then presented to the user:
    `
    {"function":{"name":"get_current_day"}}
    {"function":{"name":"generate","arguments":{"prompt":"Write a poem about $SHELLM_PREVIOUS."}}}
    `
    You are encouraged to "say" status updates in longer toolchains.
  tool_context: >-
    You are a highly intelligent agent responsible for analyzing and interpreting user input.
    You are embedded in an application that allows you to
    * modify files
    * execute code
    * access the internet
    * much, much more

    You are sitting between the user and a tool calling AI agent. You are a planning expert capable of strategic long-term thinking.
    Your mission is to transform incomplete, vague and fuzzy human input into precise instructions.
    Identify missing or incomplete information.
    Identify dependencies that need to be satisfied in order to carry out the request.
    Create a high-level strategy in chronological order to carry out the task without detailing individual solutions.
    Keep it declarative and let the AI agent pick the concrete tools.
    Hold the prose. Bullet points only.
tools:
  execute_shell_command:
    type: function
    function:
      name: execute_shell_command
      description: >-
        Constructs a shell command with arguments to carry out the request.
      parameters:
        type: object
        properties:
          command:
            type: string
            description: The shell command to execute. Bash syntax is allowed
            raw: true
        required:
          - command
      exec: '${command}'
  fork:
    type: function
    function:
      name: fork
      description: Display a static message to the user.
      parameters:
        type: object
        properties:
          message:
            type: string
            description: >-
              The message to display. Use $SHELLM_PREVIOUS here to display output
              of previous tools.
      exec: 'echo "${message}"'
  say:
    type: function
    function:
      name: say
      description: Display a static message to the user.
      parameters:
        type: object
        properties:
          message:
            type: string
            description: >-
              The message to display. Use $SHELLM_PREVIOUS here to display output
              of previous tools.
      exec: 'echo "${message}"'
  ask:
    type: function
    function:
      name: ask
      description: Ask the user a question and capture their response.
      parameters:
        type: object
        properties:
          question:
            type: string
            description: >-
              The question to display. Use $SHELLM_PREVIOUS here to display output
              of previous tools.
        required:
          - message
      exec: 'read -p "${question} " 2>/dev/tty; echo "$REPLY"'
  generate:
    type: function
    function:
      name: generate
      description: Display LLM-generated output to the user.
      parameters:
        type: object
        properties:
          prompt:
            type: string
            description: >-
              The prompt to be passed to the completion endpoint. Supports both
              Chat-like instructions and generic prediction/completion.
          json:
            type: boolean
            description: >-
              Set to true to format the output as JSON. Works only if JSON is also
              used in the prompt
        required:
          - prompt
      # language=sh
      exec: |
        generate_response "${prompt}" 200 $( [[ "${json}" == "true" ]] && echo '-j' )
  conditional:
    type: function
    function:
      name: conditional
      description: Apply .
      parameters:
        type: object
        properties:
          predicate:
            type: string
            description: >-
              Description of the subject and criteria which is then passed to a
              LLM to review and decide. Use $SHELLM_PREVIOUS here to display
              output of previous tools.
          tools:
            type: string
            description: >-
              The list of tool calls as JSON. Follow the same instructions that
              were given for the outer tools.
        required:
          - predicate
          - tools
      exec: 'echo "${message}"'
  while:
    type: function
    function:
      name: while
      description: Apply .
      parameters:
        type: object
        properties:
          predicate:
            type: string
            description: >-
              Description of the subject and criteria which is then passed to a
              LLM to review and decide. Use $SHELLM_PREVIOUS here to display
              output of previous tools.
          tools:
            type: array
            items:
              type: function
            description: >-
              The list of tool calls as JSON. Follow the same instructions that
              were given for the outer tools.
            raw: true
        required:
          - predicate
          - tools
      # language=sh
      exec: >-
        tools=$(echo '${tools}' | jq -c '.[]');
        apply_tool_calls "$tools";
        generate_response -j "${predicate}";
  #      while :; do
  #          for tool_call in "${tools[@]}"; do
  #              apply_tool_calls "$tool_call"
  #          done
  #          if ! generate_response -j "$predicate"; then
  #              break
  #          fi
  #      done
  foreach:
    type: function
    function:
      name: conditional
      description: Apply .
      parameters:
        type: object
        properties:
          predicate:
            type: string
            description: >-
              Description of the subject and criteria which is then passed to a
              LLM to review and decide. Use $SHELLM_PREVIOUS here to display
              output of previous tools.
          tools:
            type: string
            description: >-
              The list of tool calls as JSON. Follow the same instructions that
              were given for the outer tools.
        required:
          - predicate
          - tools
      exec: 'echo "${message}"'
